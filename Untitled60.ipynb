{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled60.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqpkhreoUkJbmj+jyy3fKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhil0949/Ass-1---10/blob/main/Untitled60.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZq97bcmd5NH"
      },
      "outputs": [],
      "source": [
        "1. What is feature engineering, and how does it work? Explain the various aspects of feature\n",
        "engineering in depth.\n",
        "Ans.\n",
        "Feature engineering is a machine learning technique that leverages data to create new variables that aren't in the training set. It can produce new features for both supervised and unsupervised learning, \n",
        "with the goal of simplifying and speeding up data transformations while also enhancing model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2. What is feature selection, and how does it work? What is the aim of it? What are the various\n",
        "methods of function selection?\n",
        "Ans.\n",
        "Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. \n",
        "It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve."
      ],
      "metadata": {
        "id": "thLJDIiveQlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3. Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
        "approach?\n",
        "Ans.\n",
        "The main differences between the filter and wrapper methods for feature selection are: Filter methods measure the relevance of features by their\n",
        " correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it."
      ],
      "metadata": {
        "id": "Q-9lGw5ueQoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4.\n",
        "\n",
        "i. Describe the overall feature selection process.\n",
        "\n",
        "Ans.\n",
        "The feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset. \n",
        "It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion.\n"
      ],
      "metadata": {
        "id": "Bf_oSyFJeQqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Describe the feature engineering process in the sense of a text categorization issue.\n",
        "Ans.\n",
        "Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning.\n",
        " In order to make machine learning work well on new tasks, it might be necessary to design and train better features."
      ],
      "metadata": {
        "id": "TsZYsSvgeQtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6. What makes cosine similarity a good metric for text categorization? A document-term matrix has\n",
        "two rows with values of (2, 3, 2, 0, 2, 3, 3, 0, 1) and (2, 1, 0, 0, 3, 2, 1, 3, 1). Find the resemblance in\n",
        "cosine.\n",
        "Ans.\n",
        "Cosine similarity measure for text classification\n",
        "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction.\n",
        " It is often used to measure document similarity in text analysis."
      ],
      "metadata": {
        "id": "UTDv41hseQyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7.\n",
        "i. What is the formula for calculating Hamming distance? Between 10001011 and 11001111,\n",
        "calculate the Hamming gap.\n",
        "Ans.\n",
        "To calculate the Hamming distance, you simply count the number of bits where two same-length messages differ. An example of Hamming distance 1 is the distance between 1101 and 1001 . \n",
        "If you increase the distance to 2 , we can give as an example 1001 and 1010 ."
      ],
      "metadata": {
        "id": "UqT2YlS5eQ0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8. State what is meant by &quot;high-dimensional data set&quot;? Could you offer a few real-life examples?\n",
        "What are the difficulties in using machine learning techniques on a data set with many dimensions?\n",
        "What can be done about it?\n",
        "Ans.\n",
        "High-dimensional data are defined as data in which the number of features (variables observed), p, are close to or larger than the number of observations (or data points), n. \n",
        "The opposite is low-dimensional data in which the number of observations, n, far outnumbers the number of features, p."
      ],
      "metadata": {
        "id": "BsmhDGFZeQ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9. Make a few quick notes on:\n",
        "PCA is an acronym for Personal Computer Analysis.\n",
        "\n",
        "2. Use of vectors\n",
        "\n",
        "3. Embedded technique\n",
        "\n",
        "10. Make a comparison between:\n",
        "\n",
        "1. Sequential backward exclusion vs. sequential forward selection\n",
        "\n",
        "2. Function selection methods: filter vs. wrapper\n",
        "\n",
        "3. SMC vs. Jaccard coefficient\n",
        "\n",
        "Ans.\n",
        "1.Vectors are commonly used in machine learning as they lend a convenient way to organize data. Often one of the very first steps in making a machine learning model is vectorizing the data.\n",
        " They are also relied upon heavily to make up the basis for some machine learning techniques as well.\n",
        "\n",
        "2. Embedded methods combine the qualities' of filter and wrapper methods. It's implemented by algorithms that have their own built-in feature selection methods. \n",
        "Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce overfitting.\n",
        "\n",
        "3.In forward selection you start with your null model and add predictors. In backward selection you start with a full model including all your variables and then you drop those you do not need/ are not significant 1 at a time.\n",
        "\n",
        "4. The main differences between the filter and wrapper methods for feature selection are: Filter methods measure the relevance of features by their correlation \n",
        "with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it.\n",
        "\n",
        "5. Thus, the SMC counts both mutual presences (when an attribute is present in both sets) and mutual absence (when an attribute is absent in both sets) as matches and compares it to the total number of attributes in the universe, whereas the Jaccard index only counts mutual presence as matches and compares."
      ],
      "metadata": {
        "id": "CcRXCI1BeQ5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-d62k7DzeQ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p9HvgHmYeRA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rWZDTm9seRDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}